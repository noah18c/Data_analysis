{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "50a40f10-f4b6-4dd3-b7aa-c63ed3ca3244"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Analysis\n",
    "\n",
    "# Clinic1 preamble: Exploratory Data Analysis\n",
    "\n",
    "In this clinic, first we will:\n",
    "\n",
    "* Cover a short intro to pandas series and dataframes\n",
    "* Learn how to read in and write files\n",
    "\n",
    "Then we will start learning the following that you will optimally practice during the clinic deliverable tasks :\n",
    "\n",
    "* Load files and systematically check their integrity\n",
    "* Parse columns in the dataframe to create new dataframe columns\n",
    "* Create and interpret visualizations to explore the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Pandas Library: Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a popular library for manipulating vectors, tables, and time series. We will frequently use Pandas data structures instead of the built-in python data structures, as they provide much richer functionality. Also, Pandas is **fast**, which makes working with large datasets easier.  Check out the official pandas website at [http://pandas.pydata.org/](http://pandas.pydata.org/).\n",
    "\n",
    "This tutorial is partially based on the [excellent book by Matt Harrison](https://www.amazon.com/Learning-Pandas-Library-Analysis-Visualization-ebook/dp/B01GIE03GW/).\n",
    "\n",
    "When you work with Pandas, it's handy to have a [cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) lying around. \n",
    "\n",
    "Pandas provides three data structures: \n",
    "\n",
    " * the **series**, which represents a single column of data similar to a python list\n",
    " * the **data frame**, which represents multiple series of data\n",
    " * the **panel**, which represents multiple data frames\n",
    " \n",
    "We'll mostly work with series and data frames and largely ignore panels. We will start with the series. \n",
    "\n",
    "Pandas should already be part of your anaconda installation. If not, simply run:\n",
    "\n",
    "```\n",
    "$ conda install pandas\n",
    "```\n",
    "\n",
    "To make pandas available, we'll import the module into this notebook. It is customary to import pandas as `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series are the most fundamental data structure in pandas. Let's create two simple series based on an arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = pd.Series([\"Stones\", \"Beatles\", \"Zeppelin\", \"Pink Floyd\"])\n",
    "bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "founded = pd.Series([1962, 1960, 1968, 1965])\n",
    "founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we output these objects we can see an index, also called an axis, which by default is an integer sequence starting at 0, and the associated values. \n",
    "\n",
    "| Index | Value | \n",
    "| - | - |\n",
    "| 0  |        Stones\n",
    "|1   |    Beatles\n",
    "|2  |    Zeppelin\n",
    "|3 |    Pink Floyd\n",
    "\n",
    "Pandas also tells us the data type of the values, `object` for the first series – in this case, this is a string, `int64` (a 64-bit integer) for the second.\n",
    "\n",
    "Notice that `int64` is not a Python datatype, but a C integer of 64 bit length – which, unlike Python integers – can overflow!\n",
    "\n",
    "We can also use other data types as indices, in which case the series behaves a lot like a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is the first parameter, the index is given by the index keyword\n",
    "bands_founded = pd.Series([1962, 1960, 1968, 1965, 2012],\n",
    "                          index=[\"Stones\", \"Beatles\", \"Zeppelin\", \"Pink Floyd\", \"Pink Floyd\"], \n",
    "                          name=\"Bands founded\")\n",
    "bands_founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Index | Value | \n",
    "| - | - |\n",
    "| Stones     |    1962\n",
    "| Beatles    |    1960\n",
    "| Zeppelin     |  1968\n",
    "| Pink Floyd |    1965\n",
    "| Pink Floyd |    2012\n",
    "\n",
    "Here we see something interesting: We've used the same index (Pink Floyd) twice, once for the original founding of the band, and once for the re-union starting in 2012. Also, the order of the entries is preserved. \n",
    "\n",
    "A series is both, a list and a dictionary! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the values of an array by printing the member `values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at how the index is composed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see here is that this isn't an explicit list, but rather a set of rules, similar to the ranges we've already worked with. \n",
    "\n",
    "Let's compare this to the index where we used explicit labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access individual entries as we'd access an array or a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded[\"Beatles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a method for looking up a value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.get(\"Stones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these access methods are as fast as a dictionary lookup, and much faster than a lookup in a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works also with arrays of labels, in which case the return type is a series, not a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.get([\"Stones\", \"Beatles\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when we access data with multiple indices, we don't get a simple datatype, as in the above cases, but instead get another series back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded[\"Pink Floyd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series also have indexers for label-based access: [`loc`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And one more way for looking up a value:\n",
    "bands_founded.loc[\"Stones\"]\n",
    "# this is equivalent to \n",
    "# bands_founded[\"Stones\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related to the `loc` indexer is the [`iloc`](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.iloc.html) indexer. However, instead of operating on our label index, `iloc` operates purely on position: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an `ix` indexer, which is deprecated and should not be used.\n",
    "\n",
    "These ways of accessing slices of a dataset (`loc`, `iloc`), will make more sense when we use dataframes instead of series – in dataframes, `loc` and `iloc` operate on the rows, whereas square brackets operate on the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Iterating\n",
    "\n",
    "Iteration works as you would expect: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in bands:\n",
    "    print(band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band, founded in bands_founded.items():\n",
    "    print(band + \", \" + str(founded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Updating\n",
    "Updating works largely as expected, however, you have to be careful when updating series with duplicate indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands[2] = \"The Doors\"\n",
    "bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a new item by direclty assigning it to a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands[4] = \"Zeppelin\"\n",
    "bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the indices don't have to be sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands[17] = \"The Who\"\n",
    "bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we update based on an index that occurs more than once, all instances are updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded[\"Pink Floyd\"] = 2015\n",
    "bands_founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to update a specific entry when an index is used multiple time is to use the `iloc` indexer. We can use the `iloc` array to set values based purely on position. However, all of this is rather ugly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.iloc[3] = 1965\n",
    "bands_founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Deleting \n",
    "\n",
    "Deleting is rarely done with pandas data structures, instead filters and masks are used. It's possible based on indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del bands_founded[\"Stones\"]\n",
    "bands_founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Indexing and slicing\n",
    "\n",
    "Indexing and slicing works largely like in normal python, but instead of just directly using the bracket notations, it is recommended to use `iloc` for indexing by position and `loc` for indexing by labelled indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing by position\n",
    "bands_founded.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When slicing by labelled index, the last value specified is *included*, which differs from regular Python slicing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing by index\n",
    "bands_founded.loc[\"Zeppelin\" : \"Pink Floyd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that index 17 is included\n",
    "bands.loc[1:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for series (not for data frames), `loc` and just using bracket notation is identical: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands[2:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both, `iloc` and `loc` can be used with arrays, which isn't possible in vanilla Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.iloc[[0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.loc[[\"Beatles\", \"Pink Floyd\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, all these variants can also be used with boolean arrays, which we will soon find out to be very helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded.loc[[True, False, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Masking and Filtering\n",
    "\n",
    "With pandas we can create boolean arrays that we can use to mask and filter a dataset. In the following expression, we'll create a new array that has \"True\" for every band formed after 1964:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = bands_founded > 1964\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses a technique called **broadcasting**. We can use broadcasting with various operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not particularly useful for this dataset..\n",
    "founding_months = bands_founded * 12\n",
    "founding_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a boolean mask to filter a series, as we've seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the mask to the original array\n",
    "# note that almost all of those operations return a new copy and don't modify in place\n",
    "bands_founded[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The short form here would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_founded[bands_founded > 1967]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Exploring a Series\n",
    "\n",
    "There are various way we can explore a series. We can count the number of non-null values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = pd.Series([1962, 1960, 1968, 1965, 2012, None, 2016])\n",
    "numbers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the sum, mean, median of a series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get an overview of the statistical properties of a series: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that None/NaN values are ignored here. We can drop all NaN values if we desire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = numbers.dropna()\n",
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works also for non-numerical data. Of course, we get different measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other useful methods are asking for a specific quantile, the minimum, the maximum, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.7 Sorting \n",
    "\n",
    "We can sort a series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make the sorting descending: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_numbers = numbers.sort_values(ascending=False)\n",
    "sorted_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the indices remain the same! We can **reset the indices**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't specify drop to be true, the previous indices are preserved in a separte column\n",
    "sorted_numbers = sorted_numbers.reset_index(drop=True)\n",
    "sorted_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also sort by the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix up the indices first\n",
    "new_sorted_numbers = numbers.sort_values()\n",
    "print(new_sorted_numbers)\n",
    "print(new_sorted_numbers.sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Applying a Function\n",
    "\n",
    "Often, we will want to apply a function to all values of a Series. We can do that with the [`map()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Convert an integer year into a date, assuming Jan 1 as day and month.\n",
    "def to_date(year):\n",
    "    return datetime.date(int(year), 1, 1)\n",
    "    \n",
    "new_sorted_numbers.map(to_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an incredibly powerful concept that you can use to modify series in sophisticated ways, similar to list comprehension. \n",
    "\n",
    "Another way to use the map function is to pass in a dictionary that is then applied to matching objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_sorted_numbers.map({1965:1945, 2012:1999, 1968:\"What\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We've only covered a small part of the features of Series here. Make sure to also check out resources such as the [10 minutes to pandas guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading Data\n",
    "\n",
    "Up to now, we've mainly used data that we've specified directly in code. This is, of course, not particularly scalable. We want to load data from files and eventually also connect to databases and APIs. \n",
    "\n",
    "Data is often stored in structured file formats, such as CSV, JSON, or XML. We'll encounter all of these file formats in this class.\n",
    "\n",
    "JSON\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"fruit\": \"Apple\",\n",
    "    \"size\": \"Large\",\n",
    "    \"color\": \"Red\"\n",
    "}\n",
    "```\n",
    "\n",
    "XML\n",
    "```xml\n",
    "<note>\n",
    "<to>Students</to>\n",
    "<from>Prof</from>\n",
    "<heading>Reminder</heading>\n",
    "<body>HW2 due this Friday at 11:59pm!</body>\n",
    "</note>\n",
    "```\n",
    "\n",
    "The simplest form is a CSV (Comma Separated Values) file. CSV isn't a formal file format, rather it's a table represented as a text file where the cells are separated by a delimiter. Commonly, the first row represents the header. A delimiter can be a tab character, a semicolon, a colon, etc. \n",
    "\n",
    "Many CSV files also have a special convention for dealing with text that could include the delimiter. The following text would be very hard to parse otherwise:\n",
    "```\n",
    "Artist, Album, Genre\n",
    "Michael Jackson, Bad, Pop, Funk, Rock\n",
    "``` \n",
    "\n",
    "Here, the album is of multiple genres which are separated by a comma. The comma, however, is also used to delimit the individual columns. \n",
    "\n",
    "To work around that, double-quotes are commonly used (though other escape characters are possible) to indicate that all the elements contained within the quotes are not meant to be delimiters:\n",
    "\n",
    "```\n",
    "Artist, Album, Genre\n",
    "Michael Jackson, Bad, \"Pop, Funk, Rock\"\n",
    "``` \n",
    "\n",
    "Of course, that's problematic if your text contains double-quotes.\n",
    "\n",
    "Now, it is clear that `Pop, Funk, Rock` should belong in a single cell. \n",
    "\n",
    "We've prepared a dataset based on Wikipedia's [list of best-selling albums](https://en.wikipedia.org/wiki/List_of_best-selling_albums) in the file [hit_albums.csv](./hit_albums.csv). \n",
    "\n",
    "Here is what the first couple of lines look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Artist,Album,Released,Genre,\"Certified sales (millions)\",Claimed sales (millions)\n",
    "Michael Jackson,Thriller,1982,\"Pop, rock, R&B\",45.4,65\n",
    "AC/DC,Back in Black,1980,Hard rock,25.9,50\n",
    "Pink Floyd,The Dark Side of the Moon,1973,Progressive rock,22.7,45\n",
    "Whitney Houston / Various artists,The Bodyguard,1992,\"Soundtrack/R&B, soul, pop\",27.4,44\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various ways of reading a CSV file. We'll first cover the basic read (and write) operations of Python, but will quickly move on to specific parsers for CSV files in Python and in Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic File Operations\n",
    "\n",
    "To read a file we first have to open it by specifying the file path, and specifying whether we want to read (r), write (w), both (r+), or append (a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums_file = open('hit_albums.csv', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read a whole file at once. Notice that lines are terminated with a special character, a linefeed or newline character specified as `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = albums_file.read()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print this instead, `\\n` is translated into a newline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading a file, we have to manually close it again to release the OS resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative to reading the whole file, we can read each line separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums_file = open('hit_albums.csv', 'r')\n",
    "line1 = albums_file.readline();\n",
    "print(line1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now [`split()`](https://docs.python.org/3/library/stdtypes.html#str.split) the string based on the comma, to create a simple CSV parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have called  `readline()`, the next time you call it, it will read the next line. \n",
    "\n",
    "We can also treat albums_file as a list (or better, as an iterable data structure) and loop over the file and read the data into an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for line in albums_file:\n",
    "    data.append(line.split(\",\"))\n",
    "    \n",
    "# let's not forget to close the file:\n",
    "albums_file.close()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now read individual cells or rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this **didn't take proper care of our double-quote escape of \"Pop, rock, R&B\"**. Also, numbers are still treated as strings and the newline character is also appended to the last cell. \n",
    "\n",
    "We could certainly improve our parser to handle these issues, but fortunately, there are existing methods to parse CSV files that make this easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Writing\n",
    "\n",
    "We can write by opening a file using the `w` flag. Here we also use the [`with`](https://docs.python.org/3/reference/compound_stmts.html#the-with-statement) keyword, which takes care of closing the file for us, even if things go wrong (see [this blog post](https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/) for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_file.txt', 'w') as new_file:\n",
    "    new_file.write(\"Hello World\\nAre you still spinning?\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check out this file by opening [my_file.txt](my_file.txt). Notice that the file is only guaranteed to be written if you actually close it (which, here, is take care of by the context manager invoked by the `with` statement). \n",
    "\n",
    "You can find more examples on basic file operations in the [Python Documentation](https://docs.python.org/3/tutorial/inputoutput.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Reading a CSV file with the CSV Library\n",
    "\n",
    "We can use the CSV library to help with reading the data. It takes a `delimiter` and a `quotechar` as parameters; the latter is useful for our double quotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import the csv library\n",
    "import csv\n",
    "\n",
    "# initialize the top-level array\n",
    "data_values = []\n",
    "\n",
    "# open the file and append rows as arrays to the data_values\n",
    "with open('hit_albums.csv') as csvfile:\n",
    "    # note that we can interchangably use ' and \" in general\n",
    "    # for the quotechar, however we use ' so that we can use \" without escaping\n",
    "    filereader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    # the row here is an array\n",
    "    for row in filereader:\n",
    "        print(\"Row: \" + str(row))\n",
    "        data_values.append(row)\n",
    "\n",
    "# Store the header in a separate array\n",
    "header = data_values.pop(0)\n",
    "   \n",
    "print()    \n",
    "print(header)\n",
    "print()\n",
    "print(data_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do computation on the numerical dimensions of this table, we need to convert the strings to numbers. If we just do this the simple way, it won't work: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data_values: \n",
    "    row[2] = int(row[2])\n",
    "    row[4] = float(row[4])\n",
    "    row[5] = float(row[5])\n",
    "        \n",
    "data_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the last column, `Claimed sales (millions)` doesn't have values for each row. In that case, the conversion throws the above `ValueError`. \n",
    "\n",
    "These errors are also called Exceptions. [Exceptions](https://docs.python.org/3/reference/compound_stmts.html#try) are error states that can be raised and caught:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data_values: \n",
    "    # need to try and catch the exception because the column contains NaN values\n",
    "    try:\n",
    "        row[2] = int(row[2])\n",
    "        row[4] = float(row[4])\n",
    "        row[5] = float(row[5])\n",
    "    except ValueError: \n",
    "        row[5] = None\n",
    "    \n",
    "data_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here we have matrix that we could work with. In reality, we probably would want to structure the data a little differently: Instead of treating each row as an array, we'd want to treat each dimension (column) as an array, as this makes the column homogeneous and it makes it easy to calculate means, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Reading CSV with Pandas\n",
    "\n",
    "Now, let's take a look at what it takes to read this file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hit_albums = pd.read_csv(\"hit_albums.csv\")\n",
    "hit_albums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that was different! \n",
    "\n",
    "Pandas provides the insanely powerful ['read_csv()'](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) method. Also see [the documentation](http://pandas.pydata.org/pandas-docs/stable/io.html) for more info on all I/O operations in pandas, including writing CSV files. \n",
    "\n",
    "You can pass a lot of arguments to the method, such as delimiter, quote-chars, etc., but for our case the default parameters just worked. \n",
    "\n",
    "We've also just created our first data frame! Let's look at data frames in detail next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Frames\n",
    "\n",
    "A data frame is a column-oriented data structure where each column is a pandas series.\n",
    "\n",
    "Here are two cheat sheets that might prove useful:\n",
    "[Cheat sheet 1](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "[Cheat sheet 2](http://datacamp-community-prod.s3.amazonaws.com/dbed353d-2757-4617-8206-8767ab379ab3).\n",
    "\n",
    "We've already loaded a data frame from file, but for completeness sake, let's create one in code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandInfo = pd.DataFrame({\n",
    "        \"Name\":[\"Led Zeppelin\", \"The Beatles\", \"Rolling Stones\", \"Radiohead\"],\n",
    "        \"No Members\":[4, 4, 4, 5],\n",
    "        \"No Albums\":[9, 12, 29 ,9]\n",
    "    })\n",
    "bandInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe was initialized with a dictonary of column headers as keys and column data as values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a series, a data frame has an index, which corresponds to the first column here. In this case the index was automatically generated, but as for the series, we could use explicit values for the index. \n",
    "\n",
    "We can access columns in a data frame, which returns a series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bandInfo[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bandInfo[\"Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And obviously, we can do all the things we've learned about to this column/series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous example used columns to create the data frame. We can also create a data frame from rows. This doesn't make a ton of sense in this example, but data could be available like this from your data source, like if you're parsing a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandInfo2 = pd.DataFrame([\n",
    "        {\"Name\":\"Led Zeppelin\", \"No Albums\":9, \"No Members\":4},\n",
    "        {\"Name\":\"The Beatles\", \"No Albums\":12, \"No Members\":4},\n",
    "        {\"Name\":\"Rolling Stones\", \"No Albums\":29, \"No Members\":4},\n",
    "        {\"Name\":\"Radiohead\", \"No Albums\":9, \"No Members\":5},\n",
    "    ])\n",
    "bandInfo2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a series has only one axis, a dataframe has two, one for the rows (the index or '0' axis), one for the columns (the column or '1' axis). We can check out these axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandInfo.axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access these axes directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The row axis\n",
    "bandInfo.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns axis\n",
    "bandInfo.axes[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data Frames\n",
    "\n",
    "You might have noticed that data frames are rendered in nice HTML tables within Jupyter Notebooks. For small data frames, just showing all the data makes sense, but for larger datasets, like our `hit_albums` dataset, plotting 70+ rows can be annoying, and for datasets with hundreds or thousands of rows it can be prohibitive. By default, a data frame only prints a limited number of elements (notice the `...` in row 30 of the output of `hit_albums` above – only the first 30 and last 30 are printed. \n",
    "\n",
    "When working with data, e.g., when transforming or loading a dataset, it is important to see the raw data, for example, to check if a transformation was done correctly. Often, however, it's sufficient to see a part of the data, e.g., the first couple of rows and/or the last couple of rows. We can do this with the `head()` and `tail()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head shows the first 5 rows of a datset\n",
    "hit_albums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can specify how much to show\n",
    "hit_albums.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tail shows the last five rows in a datasaet\n",
    "hit_albums.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out the dimensions of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we learn that our dataset has 77 rows and 6 columns.\n",
    "\n",
    "We can also get more info about the dataset using the info method, which is especially helpful to see the data types of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for series, we can get a rough description of the numerical values of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see any descriptions of the columns of non-numerical type. We can, however, get a summary by directly accessing a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[\"Artist\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that Michael Jackson is the top artist in this list, with five albums. Are there other artists with multiple albums in the list? We can answer that question with the value_counts() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[\"Artist\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at whether the numerical columns in our data frame are correlated using the [`corr()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html) method. By default, this calculates a Pearson correlation between the column, excluding NaN values. Not surprisingly, we see a rather strong correlation (0.81) between certified and claimed sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.iloc[:,-2:].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do transpose a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Slicing Data Frames\n",
    "\n",
    "A common task is to create subsets of a dataframe. Check out the official [user guide for more info on this](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html).  \n",
    "\n",
    "Column access/slicing works by directly using brackets `[]` on the data frame. Row access/slicing works by using the `.loc[]` indexer. \n",
    "\n",
    "We can explicitly define the the **column(s)** we want by their lables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single column\n",
    "hit_albums[\"Artist\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use an array of lables if we want multiple columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying multiple columns in an array\n",
    "hit_albums = hit_albums[[\"Artist\",\"Certified sales (millions)\", \"Claimed sales (millions)\"]]\n",
    "hit_albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing of columns requires the `iloc` operator\n",
    "\n",
    "This: \n",
    "```python\n",
    "hit_albums[\"Artist\":\"Genre\"]\n",
    "```\n",
    "Doesn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One break with the convention that rows have to be accessed via `loc` or `iloc` is simple numerical slicing. The documentation claims that's for convenience, since this is so common: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these access methods we can also update the order: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[[\"Certified sales (millions)\", \"Claimed sales (millions)\", \"Artist\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set a column to be the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed = hit_albums.set_index(\"Artist\")\n",
    "hit_albums_reindexed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing with `loc`\n",
    "\n",
    "We can retrieve **rows** and columns using the `loc` indexer by name. Depending on whether the label is unique or not, we get either a series or a data frame. \n",
    "\n",
    "Generally, `loc` is preferred over direct access via brackets. \n",
    "\n",
    "The general syntax is\n",
    "\n",
    "```\n",
    "df.loc[rows, columnns]\n",
    "```\n",
    "Here rows, columns can be explicit labels, lists of labels, or slicing operators. \n",
    "\n",
    "Here's a simple example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Meat Loaf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an example with multiple keys that returns a data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Michael Jackson\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second argument in the `loc` array can be used to access columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Michael Jackson\", \"Certified sales (millions)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example with a list of row labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[[\"Michael Jackson\", \"Meat Loaf\"], \"Certified sales (millions)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use slice operations. Remember, that slicing by label (`loc`) includes the last value, by index (`iloc`) does not. \n",
    "\n",
    "\n",
    "Note that this doesn't work if we use labels that have duplicates as indexers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Green Day\":\"Supertramp\"]\n",
    "\n",
    "# this wouldn't work\n",
    "# hit_albums_reindexed.loc[\"Green Day\":\"Michael Jackson\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be combined with slicing columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums_reindexed.loc[\"Green Day\":\"Supertramp\", [\"Certified sales (millions)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also slice columns with loc. Let's re-load the full dataset first:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums = pd.read_csv(\"hit_albums.csv\")\n",
    "full_hit_albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a slice containing all rows and the columns from Artist to Released: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[:,\"Artist\":\"Released\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a slice for the first 10 rows and columns Artists to Released: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[:10,\"Artist\":\"Released\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same thing using `iloc`, i.e., index based slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.iloc[0:10, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Broadcasting\n",
    "\n",
    "Of course, we can use broadcasting and filtering based on boolean masks just as we do for series.\n",
    "\n",
    "Here we boradcast an operation on a series and set it to a new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums[\"Certified sales\"] =  full_hit_albums[\"Certified sales (millions)\"] * 1000000\n",
    "full_hit_albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we filter out all of the albums that were released before 1990. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = full_hit_albums[\"Released\"] > 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, short: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hit_albums.loc[full_hit_albums[\"Released\"] > 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Missing values\n",
    "\n",
    "Let's take care of some NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hit_albums.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way would be to just drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.dropna().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, that's pretty aggressive here – we're dropping more than half of our dataset. We could also just remove the claimed sales. \n",
    "\n",
    "An alternative would be to fill the missing values with our best guess: \n",
    "We can use the [`fillna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) on it.\n",
    "\n",
    "We could replace all NaN values with 0s: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.fillna(0).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought it's probably better to use the forward fill (`ffill`) method here. By default, `ffill` will use the value of the previous row to fill a NaN value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.fillna(method=\"ffill\").tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It probably makes more sense to use forward fill along the columns, so that the certified sales are filled into the claimed sales if necessary. We can do that by specifying `axis=1` so that `ffill` works on the columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the result here\n",
    "hit_albums = hit_albums.fillna(axis=1, method='ffill')\n",
    "hit_albums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Grouping Data Frames\n",
    "\n",
    "Very often, we want to aggregate data. Given the hit-albums dataset, for example, we might want to ask how many albums each artist in that list has sold in total. We can do these aggregations using the [group-by method](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify a column to group by, for example, \"Artist\". We can look at the groups created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = hit_albums.groupby(\"Artist\")\n",
    "grouped.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the keys map to a set of indices. For example, Michael Jackson's albums are found at indices [0, 10, 16, 65, 66].\n",
    "\n",
    "Once we have created these groups, we can specify what to do with it.\n",
    "\n",
    "Pandas has a couple of built in functions to make this easy. For example, we can just call `sum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.sum().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that we've summed up the data for each column. However, note that NaN plus some number is still NaN, which is treated as 0 here. So let's work with a slice of the dataframe instead. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we sort them, and have a nice result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.sum().sort_values(\"Certified sales (millions)\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is the `count` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.count().sort_values(\"Certified sales (millions)\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A very generic solution is the `agg()` function, which we can pass a function to do things with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#here we pass the sum function, which calcualtes the sum of a list, to the group\n",
    "grouped.agg(sum).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass in numpy functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "grouped.agg(np.max).sort_values(\"Certified sales (millions)\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an aggregation with an in-line function definition where we still create the sum, but also multiply by a million. We use a [lambda expression](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions) to define the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg(lambda rows : sum([cell * 1000000 for cell in rows])).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda expressions are just a different way of defining a function in line, without assigning it a name. They only work for a single statement. \n",
    "\n",
    "Here is a simple lambda expression, which returns a function, which we assign to the variable add:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = lambda a, b : a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's take this apart: \n",
    "\n",
    "```python\n",
    "[cell * 1000000 for cell in rows]\n",
    "```\n",
    "\n",
    "This part is a list comprehension, that takes an array `rows` and multiplies every element with 1,000,000. \n",
    "\n",
    "The surrounding `sum` is a call to the sum function, so adds up the values in the just modified array. \n",
    "\n",
    "And finally, the lambda expression packs all of this in a function. \n",
    "\n",
    "Here is a different, longer way to write this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumUpAndMultiplyByMillion(rows):\n",
    "    multiplied_rows = [cell * 1000000 for cell in rows]\n",
    "    summed_value = sum(multiplied_rows)\n",
    "    return summed_value\n",
    "\n",
    "grouped.agg(sumUpAndMultiplyByMillion).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A note on buit-in Plotting\n",
    "\n",
    "Dataframes have built-in plotting capabilities based on the [matplotlib](http://matplotlib.org/) library. Refer to the data visualization notebook for all capabilities of plotting with Pandas.\n",
    "\n",
    "First, we have to import the matplotlib library, and tell Jupyter to display the images directly here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "# This next line tells jupyter to render the images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can simply call the plot attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also selected certain columns using labelled indexes and then plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[\"Certified sales (millions)\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use bar-charts instead of line-charts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_albums[[\"Certified sales (millions)\", \"Claimed sales (millions)\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is a line chart. This doesn't make much sense, since it's mixing index of the row with sales. We're better off plotting only the two different sales figures.\n",
    "\n",
    "A better way to compare certified and claimed sales is a scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is currently broken due to a pandas bug. \n",
    "hit_albums.plot.scatter(x=\"Certified sales (millions)\", y=\"Claimed sales (millions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a histogram: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hit_albums['Certified sales (millions)'].plot.hist(bins=10, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Of course there is more sophisticated plotting (please follow the visualization notebook from the lectures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, you can start with the clinic"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbpresent": {
   "slides": {
    "19a6495f-8346-4b23-a98a-c7115941e8f0": {
     "id": "19a6495f-8346-4b23-a98a-c7115941e8f0",
     "prev": null,
     "regions": {
      "d6523b36-7204-4001-8a6c-37c431b18d26": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "id": "d6523b36-7204-4001-8a6c-37c431b18d26"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
